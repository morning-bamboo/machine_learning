{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4afb30-d3ad-435d-848c-c148789686b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "#Convert a collection of text documents to a matrix of token counts/numerical feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a6f721-de98-4902-9102-734068731d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb5e5c4-8a6b-4b58-8b1a-c96c0448ab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505a32a7-ebc1-4197-9615-36d292928b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
       "       'second document', 'the first', 'the second', 'the third',\n",
       "       'third one', 'this document', 'this is', 'this the'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "x2 = vectorizer2.fit_transform(corpus)\n",
    "vectorizer2.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47745813-d10f-4100-a5d9-ebe318d3ec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a50364-fab7-4a63-9e7e-1c496f8057ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and this is', 'document is the', 'is the first', 'is the second',\n",
       "       'is the third', 'is this the', 'the first document',\n",
       "       'the second document', 'the third one', 'this document is',\n",
       "       'this is the', 'this the first'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3 = CountVectorizer(analyzer='word', ngram_range=(3, 3))\n",
    "x3 = vectorizer3.fit_transform(corpus)\n",
    "vectorizer3.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c3f399-f855-40b9-b730-f84f4e45c897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e70a8cb-e0ba-4d93-b838-7304dc80f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#`Pipeline` allows you to sequentially apply a list of transformers to preprocess the data and, if desired, \n",
    "# conclude the sequence with a final term:`predictor` for predictive modeling.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#The multinomial Naive Bayes classifier is suitable for classification with discrete features (eg, word counts for text classification).\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),(\"nb\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6dbbfc1-a762-4ebd-8db8-5075c95c0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.fit(x_train,y_train)\n",
    "# pipe.score(x_test,y_test)\n",
    "# pipe.predict(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770ed5e-667b-4507-ac9c-b9fb9667dc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
